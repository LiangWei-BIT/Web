<head>
    <title>Liang Wei</title>
    <!--<meta name="viewport" content="width=device-width, initial-scale=1.0">-->
	<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <!-- Bootstrap -->
    <link rel="stylesheet" href="http://cdn.bootcss.com/twitter-bootstrap/2.3.2/css/bootstrap.min.css">
	
	<style>
a.one:link,a.one:visited
{
display:block;
width:92px;
font-weight:bold;
color:#FFFFFF;
background-color:#bebebe;
text-align:center;
padding:4px;
text-decoration:none;
text-transform:uppercase;
}
a.one:hover,a.one:active
{
background-color:#99CCFF;
}
</style>
  </head>
  <body>
    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="http://cdn.bootcss.com/jquery/1.10.2/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="http://cdn.bootcss.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
  </body>
<div class="container">
	<div class="row">
		<div class="span12">
		<br><br><br/>
		 <p class="text-center" style="font-size:180%;"> 
						<strong>Tracking Occluded Objects and Recovering Incomplete Trajectories
                               by <br><br>Reasoning about Containment Relations and Human Actions</strong>
		</p>
		</div>
	</div>
	<div class="row">
		<div class="span12">
		<br><br>
		 <p class="text-center" style="font-size:120%;">
		 Wei Liang<sup>1,2</sup> &nbsp;&nbsp;
		 Yixin Zhu<sup>2</sup> &nbsp;&nbsp;
		 Song-Chun Zhu<sup>2</sup> &nbsp;&nbsp;
		</p>
		 <p class="text-center" style="font-size:120%;">
		 <sup>1</sup>Beijing Institute of Technology &nbsp;&nbsp;
         <sup>2</sup>University of California, Los Angeles, USA&nbsp;&nbsp;
		</p>
		</div>
	</div>
	<div class="row">
		<div class="span1">
					
		</div>
		<div class="span5">
		<img alt="100x100" src="./aaai_tracking_files/Project1_AAAI.png" style="width:500px; height:400px"/>
		
		 
		</div>
		<div class="span5">
		<br><br><br><br><br><br>
		<p style="font-size:100%;text-align:justify;">
		A scenario for tracking occluded objects in an indoor scene. The dashed lines represent the inferred trajectories and different colors indicate different objects in the scene. By explicitly reasoning about containment relations, the proposed algorithm is capable of recovering full trajectories of objects even they are contained or occluded by other objects in the video.
		    </p>
		</div>
		<div class="span1">
		
		</div>
	</div>
	<br>
	<div class="row">
		<div class="span12">
			<h4>
				Abstract
			</h4>
			 <p style="font-size:100%;text-align:justify;">
				This paper studies a challenging problem of tracking severely occluded objects in long video sequences. The proposed method reasons about the containment relations and human actions, thus infers and recovers occluded objects identities while contained or blocked by others. There are two conditions that lead to incomplete trajectories: i) Contained. The occlusion is caused by a containment relation formed between two objects, e.g., an unobserved laptop inside a backpack forms containment relation between the laptop and the backpack. ii) Blocked. The occlusion is caused by other objects blocking the view from certain locations, during which the containment relation does not change. By explicitly distinguishing these two causes of occlusions, the proposed algorithm formulates tracking problem as a network flow representation encoding containment relations and their changes. By assuming all the occlusions are not spontaneously happened but only triggered by human actions, an MAP inference is applied to jointly interpret the trajectory of an object by detection in space and human actions in time. To quantitatively evaluate our algorithm, we collect a new occluded object dataset captured by Kinect sensor, including a set of RGB-D videos and human skeletons with multiple actors, various objects, and different changes of containment relations. In the experiments, we show that the proposed method demonstrates better performance on tracking occluded objects compared with baseline methods.

		    </p>
			
		</div>
	</div>
	<div class="row">
		<div class="span12">
		<br>
			<h4>
				Publication
			</h4>

  <p align="left"><strong>Tracking Occluded Objects and Recovering Incomplete Trajectories by Reasoning about Containment Relations and Human Actions</strong><br>

    Wei Liang,
	Yixin Zhu,
	and Song-Chun Zhu

	<!--<a href="http://www.stat.ucla.edu/~ybzhao/"  style="vertical-align: middle;color:#99CCFF">Yibiao Zhao</a>,-->
    
	<br> 2018 AAAI Conference on Artificial Intelligence ( <b>AAAI</b>)
	<br><a href="http://iitlab.bit.edu.cn/mcislab/~liangwei/projects/aaai_tracking/AAAI_2018_Tracking_by Reasoning.pdf"  style="vertical-align: middle;color:#99CCFF">Paper</a>
	<span class="bodyText STYLE3">, <a href="http://iitlab.bit.edu.cn/mcislab/~liangwei/projects/aaai_tracking/AAAI.mp4"  style="vertical-align: middle;color:#99CCFF">Video</a>
	<br>
	<br>
	</span></p>
	<h4>BibTex</h4>

<p align="left">@inproceedings {wei2018container,<br>

&nbsp;&nbsp;&nbsp;
title=
{Tracking Occluded Objects and Recovering Incomplete Trajectories by Reasoning about Containment Relations and Human Actions},<br>

&nbsp;&nbsp;&nbsp; author={Liang, Wei and Zhu, Yixin and Zhu, Song-Chun},

<br> &nbsp;&nbsp;&nbsp;

booktitle = {<span lang="EN-US" style="FONT-FAMILY: &quot;Times New Roman&quot;">Thirty-Second AAAI Conference on Artificial Intelligence (AAAI)</span>},<br>

&nbsp;&nbsp;&nbsp; year={2018}<br>

}</p>

<br><br>
<p class="text-center">
<iframe width="740" height="480" src="http://iitlab.bit.edu.cn/mcislab/~liangwei/projects/aaai_tracking/AAAI.mp4" frameborder="0" allowfullscreen></iframe>
</p>
			
		</div>
		</div>
		<br><br>
			<div class="row">
				<div class="span1">
				<br>
				   <img alt="100x100" src="./img/huibiao.png" style="width:60px; height:60px"/>
				</div>
				<div class="span4">
				<ul class="unstyled">
				<br>
				   <li style="font-size:130%">媒体计算与智能系统实验室</li>
				  <br><li style="font-size:100%">Media Computing and Intelligent Systems Lab</li>
				   </ul>
				</div>
				<div class="span7">
					<p class="text-center" style="font-size:110% font-family:Times,Georgia,New Century Schoolbook">
					<br>
						Beijing Institute of Technology Copyright Address: 5 South Zhongguancun
						<br><br>Street, Haidian District, Beijing Postcode: 100081
					</p>
				</div>
				<br><br>
			</div>
			<div class="row">
			<br><br>
			</div>
	
</div>